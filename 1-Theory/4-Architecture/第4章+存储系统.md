    

第4章 存储系统

- 存储系统概述
    
    - 存储系统的层次结构
        
        - 存储器有什么：CPU内部的通用寄存器组、一级Cache、二级Cache、三级Cache，主板上的主存储器（主存），主板外的联机（在线）磁盘存储器，脱机（离线）的磁带、光盘存储器等
            
        - 存储系统：将两种或以上的存储器用硬件、软件结合并进行管理，就构成存储系统
            
        - 存储系统层次结构
            
        - 特点
            
        
    - 存储器的分类
        
        - 按存储信息的介质：半导体存储器、磁盘存储器、光盘存储器
            
        - 按在计算机中的用途
            
        - 按存放信息的易失（挥发）性
            
        - 按存取方式分类
            
        - 按存储器的读写功能分类
            
        
    - 存储器的性能指标
        
        - 存储容量
            
        - 存储器速度
            
        - 可靠性
            
        - 功耗：对于电池供电的系统非常重要。低功耗的存储器构成存储系统，降低了对电池容量的要求，也可以提高存储系统的可靠性
            
        - 价格：通常以每千字节KB或每兆字节MB的价格来衡量
            
        
    
- 主存储器
    
    - 背景
        
        - 内部存储器，狭义指主存储器MM(Main Memory)，广义则包括主存、高速缓存、虚拟存储器在内的存储层次
            
        - 主存是最早出现的存储层次，是冯诺依曼计算机到目前所有计算机中不可或缺的功能部件
            
        - 主存是正在执行的程序和作用数据的存放地，其容量和速度对计算机性能有直接影响
            
        - 现代计算机主存都是半导体存储器集成芯片
            
        
    - 主存的结构
        
        主存的硬件设计使用物理结构，程序访问主存使用逻辑结构
        
        - 主存的逻辑结构
            
        - 主存的物理结构
            
        
    - 随机读写存储器RAM
        
        - 静态读写存储器SRAM(Static RAM)：
            
            是构成小容量高速存储器最常用的部件，如高速缓冲存储器Cache
            
            - 常规RAM芯片的外部有地址线、数据线和控制信号线，地址线在芯片内部译码，可选中芯片内部的相应存储单元
                
            - 例如，某SRAM芯片上有n条地址线，这些地址线索能表示的地址编码有2n2^n2n​​​ 种，这意味着该芯片内部有2n2^n2n​​​ 个存储单元
                
            - SRAM存储元电路
                
            
        - 动态读写存储器DRAM(Dynamic RAM)：
            
            - 速度快（仅次于SRAM）、集成度高、功耗小、单位容量的价格低，目前计算机的内存条都采用了DRAM
                
            - 发展：传统异步DRAM芯片→\to→​​​ 同步DRAM(Synchronous DRAM)→\to→​​​ 双倍数据率同步DRAM(Double Data Rate SDRAM)
                
            - DRAM存储元电路：课本P104P_{104}P104​​​​​​​​
                
            - 典型DRAM芯片：DDR4 SDRAM P105∼P108P_{105}\sim P_{108}P105​∼P108​​​​​​​​​​​​​​​​​​​​
                
            - DRAM工作过程：P108∼P111P_{108}\sim P_{111}P108​∼P111​​​​​​​​​​​​​​​​​​​​
                
            
        
    - 只读存储器ROM
        
    - 相联存储器
        
        根据内容确定内容对应的地址或者依据内容寻找相关的其他内容
        
        - 构成
            
            - 检索寄存器
                
            - 屏蔽寄存器
                
            - 存储体
                
            - 比较电路
                
            - 匹配寄存器
                
            - 数据寄存器
                
            
        - 应用
            
            - 高速缓冲存储器Cache的地址映射表
                
            - 页式虚拟存储器的块表
                
            
        
    - 主存储器设计方法
        
        - 要解决的主要问题：CPU如何通过地址寻址到某个存储器芯片中的某个存储单元，即地址译码器的设计问题
            
        - 存储器芯片的连接方式
            
            - 字扩展
                
            - 位扩展
                
            - 位和字同时扩展
                
            
        - 用存储器芯片构成主存模块
            
            - 用SRAM芯片构成主存模块
                
            - 用EPROM芯片构成主存模块
                
            - 用EEPROM芯片构成主存模块
                
            - 内存条（用DRAM芯片构成主存）
                
                - RDIMM
                    
                - LRDIMM
                    
                - UDIMM
                    
                - SODIMM
                    
                - ECC UDIMM/ECC SODIMM
                    
                
            
        - 存储器与CPU的速度协调
            
        - 多体交叉存储器
            
            - 多体并行访问
                
            - 多体交叉访问
                
            
        
    
- 高速缓冲存储器
    
    - 工作原理
        
    - 地址映射与变换
        
        - 全相联地址映射方式
            
        - 直接地址映射方式
            
        - 组相联地址映射方式
            
        
    - 替换算法
        
        未命中且Cache中没有空闲块时，需要在Cache中选择一个替换块，用于放置新调入的主存块
        
        - 随机替换算法RAND
            
            - 随机函数发生器产生需替换的Cache块号
                
            - 没有考虑信息的历史及使用情况，虽然实现简单，但可能会降低命中率
                
            
        - 先进先出算法FIFO(First In First Out)
            
            - 最先装入Cache的主存块最先替换出去
                
            - 只考虑了信息的历史状况而没有考虑使用情况，导致命中率不高
                
            
        - 近期最少使用算法LRU(Least Recently Used)
            
            - 将近期最少使用的Cache块替换出去
                
            - 需要对每个Cache块设置一个计数器，某块每命中一次，就将其计数器清0而其他计数器加1，当需要替换时，将计数值最大的块替换出去
                
            - 由于Cache的工作原理建立在局部性原理上，故此算法命中率高于前两种
                
            
        - 最不经常使用算法LFU(Least Frequently Used)
            
            - 将一段时间内被访问次数最少的Cache块替换出去
                
            - 需要对每个Cache块设置一个计数器，开始调入时计数器为0，每被访问一次，计数器加1，需要替换时，将计数值最小的块替换出去并将所有各块的计数器清零
                
            - 将计数器限定在两次替换的时间间隔内，不能完全反映近期的访问情况
                
            
        - 最优替换算法OPT(Optional Replacement)
            
            - 程序执行两次，第一遍执行记录各Cache块地址的使用情况，由此找出需要替换出去的块，在第二次及之后执行中可以使命中率达到最高
                
            - 显然，这种方法是不实用的，仅作衡量其他算法的标准
                
            
        
    - 更新策略
        
        CPU对数据Cache单元写，改变其内容​​​​​​​​​​​​​​​​ 主存相应的数据内容，程序Cache是只读的不存在更新问题
        
        - 写回法
            
            - 当CPU写Cache命中时，只将数据写入Cache而不立即写入主存，只有当CPU改写过的块被替换出去时才写回主存；如果CPU写Cache未命中，则先将相应主存块调入Cache中，再在Cache中进行写入操作，对主存的修改仍留待该块替换出去时进行
                
            - 要实现写回法，需要对Cache的每一块增设一位修改标志，以便在该块被替换时，根据此标志决定是将该块写回主存还是丢弃
                
            - 写修改是在Cache中进行的，可以发生很多次，但对主存的修改只有最后替换时的一次
                
            - 速度比写直达法快，但在替换前的这段时间里存在主存和Cache内容不一致的问题
                
            
        - 写直达法
            
            又称全写法
            
            - 当CPU写Cache命中时，在将数据写入Cache的同时也写入主存；为命中时直接对主存进行写入修改，而后可以将修改过的主存块调入Cache或不调入Cache
                
            - 不需要设置修改标志，同时修改Cache和主存达到了高一致性，但速度较慢
                
            
        
    - Cache性能测量
        
        - 命中率Hit Rate
            
            - 命中率h=NCN×100%h=\frac{N_C}{N} \times 100 \%h=NNC​​×100%​​​​​​​​​​​​​​​​​​​​​​​​​​​​​
                
            - 其中NCN_CNC​​​​ 为CPU在Cache中访问到所需信息的次数，N为CPU访问Cache-主存系统的总次数，相应的m=1−hm=1-hm=1−h​​​​​ 表示未命中率、缺失率、脱靶率
                
            - 显然，命中率越高CPU在Cache中访问到信息的机会越多，访问速度越快
                
            
        - 平均访问时间Average Access Time
            
            - 平均访问时间T=h×TC+(1+h)×(TC+TM)=TC+(1−h)×TMT=h\times T_C+(1+h)\times (T_C+T_M)=T_C+(1-h)\times T_MT=h×TC​+(1+h)×(TC​+TM​)=TC​+(1−h)×TM​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​
                
            - 其中TCT_CTC​​​​ 是Cache的访问时间，TMT_MTM​​​​ 是主存访问时间，h×TCh\times T_Ch×TC​​​​​​​​​​​​ 是命中时直接访问Cache所用的时间，(1−h)×(TC+TM)(1-h)\times (T_C+T_M)(1−h)×(TC​+TM​)​​​​​​​​​​​​​​​​​​​​​ 是为命中时从主存加载数据到Cache并访问Cache所用的时间
                
            - 通常TM≫TCT_M\gg T_CTM​≫TC​​​​​​​​​​​ ，所以命中率很高时，Cache-主存系统的平均访问时间接近于Cache的访问时间TCT_CTC​​​​ ，表明Cache性能良好
                
            - 增加块尺寸，采用高速的块传输技术（如主存多体交叉结构），可以减少调入/替换开销
                
            
        - 加速比Speedup Ratio
            
            - 根据Amdahl定律，Cache-主存系统的加速比定义为SP=TMT=TMTC+(1−h)×TM=11−h+1rS_P=\frac{T_M}{T}=\frac{T_M}{T_C+(1-h)\times T_M}=\frac{1}{1-h+\frac{1}{r}}SP​=TTM​​=TC​+(1−h)×TM​TM​​=1−h+r1​1​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​
                
            - 其中，r=TMTCr=\frac{T_M}{T_C}r=TC​TM​​​​​​​​​​​​​​​​​​​ 是从主存到Cache速度提升的倍数，块大小确定后，命中率越高，加速比越大，极限值为r
                
            
        - 成本
            
            - 假设主存与Cache的容量分别为S1S_1S1​​​​ 和S2S_2S2​​​​ ，主存和Cache的价格分别为C1C_1C1​​​​ 和C2C_2C2​​​​ ，显然S1≫S2，C1<C2S_1\gg S_2，C_1<C_2S1​≫S2​，C1​<C2​​​​​​​​​​​​​​​​​​​ ，则Cache-主存系统的平均价格为：
                
            - C=C1×S1+C2×S2S1+S2C=\frac{C_1\times S_1+C_2\times S_2}{S_1+S_2}C=S1​+S2​C1​×S1​+C2​×S2​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​​ ，因此，对于S1≫S2S_1\gg S_2S1​≫S2​​​​​​​​​​​ ，Cache-主存系统的价格接近于主存价格
                
            
        
    - Cache性能提高
        
        - 多级Cache结构
            
            - 最靠近CPU的为L1 Cache，容量比较小，但速度很高与CPU相匹配；最靠近主存的为Ln Cache，容量较大，速度较低
                
            - 上一级Cache未命中时，到下一级Cache中去搜索
                
            - 这样的设计可以使多级Cache结构总体上速度完全匹配CPU，并且降低了缺失率
                
            - 总缺失率=L1缺失率×L2缺失率×···×Ln缺失率
                
            - 另外：
                
                - 对于多核处理器，L1、L2、L3Cache都集成在处理器内部，每个核拥有自己的L1和L2Cache
                    
                - L1 Cache有独立的指令Cache和数据Cache组成，并且这两部分可以独立工作、并行访问
                    
                - 最末一级Cache由所有的内核共享
                    
                
            
        - 降低Cache的缺失率
            
            - Cache缺失类型
                
                对于容量一定的Cache，强制缺失和容量缺失是非常固定的，由处理器芯片的成本或空间可利用性决定，而冲突缺失收地址映射方案影响
                
                - 强制缺失Compulsory Misses：
                    
                    - 程序执行时第一次访问的主存块，因其一定不在Cache中而造成的缺失，大多情况下不可避免
                        
                    
                - 容量缺失Capacity Misses：
                    
                    - Cache容量有限，当其已满且又遇到程序欲访问的主存块未在Cache中时，出现容量缺失，最常见的Cache缺失
                        
                    
                - 冲突缺失Conflict Misses：
                    
                    - Cache中有空闲块，但地址映射方案将有用的Cache块替换掉，使得未来可能因在次使用被替换掉的有用块而造成的缺失
                        
                    - 主要发生在采用直接地址映射方案的Cache方案中
                        
                    
                
            - 解决方案简述
                
                - 解决冲突缺失——改变地址映射策略
                    
                - 减少容量缺失——增加Cache容量
                    
                - 降低强制缺失——通过软件或硬件预取主存块
                    
                
            - 解决方案详悉
                
                - 合理设计Cache尺寸
                    
                    - 现象：根据程序执行的局部性，Cache块越大缺失率会越高；但在Cache容量一定的情况下，Cache块的尺寸越大，块的数量越少，块的替换越频繁，缺失率也会上升
                        
                    - 方案：在Cache容量一定的情况下，寻找使缺失率达到最低点的块尺寸B最佳B_{最佳}B最佳​​​​​​​
                        
                    - 另外：增加块尺寸也会增加未命中的开销
                        
                    
                - 合理增加Cache容量
                    
                    - Cache容量变化的影响
                        
                        - 容量较小时，随着容量的增加缺失率快速下降，进一步容量增加时下降速度变缓，当Cache的容量装得下CPU要执行的所有程序和数据时，命中率达到100%
                            
                        - Cache容量越大，B最佳B_{最佳}B最佳​​​​​​​ 会越大，对应缺失率也会越小
                            
                        
                    - Cache容量增加的问题
                        
                        - 成本增加：因此需要在容量和低缺失率之间寻找一个平衡点
                            
                        - 硬件复杂度提高，延时增加，命中所需要的时间增加
                            
                        
                    
                - 合理设置相连度
                    
                    - Cache容量一定时，
                        
                        - 采用直接地址映射方式的Cache具有较低的命中率
                            
                        - 采用全相联地址映射方式的Cache具有较高的命中率
                            
                        - 采用组相联地址映射方式的Cache具有高命中率和低复杂度的平衡，故此方案最常见
                            
                        
                    - 在组相联地址映射方案中，提高相连度（相连路数）有助于降低缺失率，实测结果表明不超过8路组相联是最佳方案
                        
                    
                - 硬件预取
                    
                    解决强制缺失的有效方法
                    
                    - 在Cache之外增加专门的硬件，通过一定的算法判断哪些指令和数据在近期极有可能会被访问到，在主存空闲时提前将这些指令和数据装入Cache
                        
                    - 但是如果预取影响了对正常未命中的处理，会降低性能
                        
                    
                - 编译优化
                    
                    - 通过编译器优化输出代码，无须修改硬件，使编译器在不影响程序运行结果的情况下，改变程序中模块或指令的位置，改善指令和数据访问的时间和空间局部性，从而降低缺失率
                        
                    
                
            
        - 减少Cache开销
            
            减少Cache命中与未命中时的开销
            
            - Cache访问流水化：
                
                - 将L1 Cache的访问过程改造成流水线方式，可以提高时钟频率及访问Cache的带宽
                    
                
            - 非阻塞Cache技术：
                
                - 在Cache未命中、启动主存装入新块时，Cache仍允许CPU访问其它命中的数据
                    
                - 对于流水线方式、允许指令乱序执行的计算机，非阻塞Cache技术可以明显提升性能，但大大增加了Cache控制器的复杂度
                    
                
            - 使读未命中优先于写：
                
                - 如果Cache读未命中且Cache被替换的块需要写回主存，可以先将被替换的块存入写缓冲器，然后从主存把需要的块装入Cache，最后再把替换的块从写缓冲器写入主存
                    
                
            
        
    
- 虚拟存储器
    
- 外部存储器（外部存储器）
    

以上内容整理于 [幕布文档](https://mubu.com?s=export-pdf)